point_cloud_range: [-20.0, -80.0, -10.0, 140.0, 80.0, 0.0]
post_center_range: [-25.0, -85.0, -10.0, 145.0, 85.0, 0.0]

voxel_size: [0.1, 0.1, 0.2]
image_size: [256, 704]
grid_size: [1600, 1600, 51]

voxel_max_points: 10
voxel_max_voxels: [120000, 120000]

xbound: ${[point_cloud_range[0], point_cloud_range[3], voxel_size[2] * 2]}
ybound: ${[point_cloud_range[1], point_cloud_range[4], voxel_size[2] * 2]}
zbound: ${[point_cloud_range[2], point_cloud_range[5], point_cloud_range[5] - point_cloud_range[2]]}
dbound: [1.0, 60.0, 0.5]

samples_per_gpu: 6
workers_per_gpu: 6

max_epochs: 6
gt_paste_stop_epoch: 4

optimizer:
  type: AdamW
  lr: 2.0e-4
  weight_decay: 0.01

momentum_config:
  policy: cyclic
  cyclic_times: 1
  step_ratio_up: 0.4

lr_config:
  policy: CosineAnnealing
  warmup: linear
  warmup_iters: 500
  warmup_ratio: 0.33333333
  min_lr_ratio: 1.0e-3

optimizer_config:
  grad_clip:
    max_norm: 25
    norm_type: 2

augment2d:
  resize: [[0.38, 0.55], [0.48, 0.48]]
  bot_pct_lim: [[0.2, 0.6], [0.4, 0.4]]
  rotate: [-5.4, 5.4]
  gridmask:
    prob: 0.1
    fixed_prob: true
    max_epoch: 5

augment3d:
  scale: [0.9, 1.1]
  rotate: [-0.78539816, 0.78539816]
  translate: 0.5

model:
  fuser:
    type: ConvFuser
    in_channels: [80, 256]
    out_channels: 256
  encoders:
    camera:
      backbone:
        type: SwinTransformer
        embed_dims: 96
        depths: [2, 2, 6, 2]
        num_heads: [3, 6, 12, 24]
        window_size: 7
        mlp_ratio: 4
        qkv_bias: true
        qk_scale: null
        drop_rate: 0.
        attn_drop_rate: 0.
        drop_path_rate: 0.2
        patch_norm: true
        out_indices: [1, 2, 3]
        with_cp: false
        convert_weights: true
        init_cfg:
          type: Pretrained
          checkpoint: https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth
      neck:
        type: GeneralizedLSSFPN
        in_channels: [192, 384, 768]
        out_channels: 256
        start_level: 0
        num_outs: 3
        norm_cfg:
          type: BN2d
          requires_grad: true
        act_cfg:
          type: ReLU
          inplace: true
        upsample_cfg:
          mode: bilinear
          align_corners: false
      vtransform:
        type: DepthLSSTransform
        in_channels: 256
        out_channels: 80
        image_size: ${image_size}
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        xbound: ${xbound}
        ybound: ${ybound}
        zbound: ${zbound}
        dbound: ${dbound}
        downsample: 2
    lidar:
      voxelize:
        max_num_points: ${voxel_max_points}
        point_cloud_range: ${point_cloud_range}
        voxel_size: ${voxel_size}
        max_voxels: ${voxel_max_voxels}
      backbone:
        type: SparseEncoder
        in_channels: ${use_dim}
        sparse_shape: ${grid_size}
        output_channels: 128
        order:
          - conv
          - norm
          - act
        encoder_channels:
          - [16, 16, 32]
          - [32, 32, 64]
          - [64, 64, 128]
          - [128, 128]
        encoder_paddings:
          - [0, 0, 1]
          - [0, 0, 1]
          - [0, 0, [1, 1, 0]]
          - [0, 0]
        block_type: basicblock
