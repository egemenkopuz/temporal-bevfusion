{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\", \"tools\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.tumtraf_create_temporal_split import TemporalSequenceDetails, create_sequence_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = (\n",
    "        \"CAR\",\n",
    "        \"TRAILER\",\n",
    "        \"TRUCK\",\n",
    "        \"VAN\",\n",
    "        \"PEDESTRIAN\",\n",
    "        \"BUS\",\n",
    "        \"MOTORCYCLE\",\n",
    "        \"OTHER\",\n",
    "        \"BICYCLE\",\n",
    "        \"EMERGENCY_VEHICLE\",\n",
    "    )\n",
    "\n",
    "root_path = \"../data/tumtraf-i\"\n",
    "overall_summary = {x:{} for x in [\"train\", \"val\", \"test\"]}\n",
    "splits = [\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze(root_path:str, split:str) -> Dict[str, Any]:\n",
    "    if not os.path.exists(os.path.join(root_path, split)):\n",
    "        return None\n",
    "\n",
    "    print() # for new line\n",
    "    sequence_data: Dict[str, TemporalSequenceDetails] = create_sequence_details(os.path.join(root_path, split))\n",
    "\n",
    "    img_label_s1_folder = os.path.join(\n",
    "        root_path, split, \"labels_point_clouds\", \"s110_lidar_ouster_south\"\n",
    "    )\n",
    "    img_label_s1_paths = sorted(glob(os.path.join(img_label_s1_folder, \"*\")))\n",
    "\n",
    "    total_not_only_prev = 0\n",
    "    total_not_only_next = 0\n",
    "    total_not_both = 0\n",
    "\n",
    "    data = {}\n",
    "\n",
    "    for x in img_label_s1_paths:\n",
    "        img_label_s1_json_path = os.path.join(x)\n",
    "        json_data = None\n",
    "        with open(img_label_s1_json_path, \"r\") as f:\n",
    "            json_data = json.load(f)\n",
    "            frame_idx = list(json_data[\"openlabel\"][\"frames\"].keys())[0]\n",
    "            frame_properties = json_data[\"openlabel\"][\"frames\"][frame_idx][\"frame_properties\"]\n",
    "            token = frame_properties[\"token\"]\n",
    "            prev = frame_properties[\"prev\"]\n",
    "            next = frame_properties[\"next\"]\n",
    "            scene_token = frame_properties[\"scene_token\"]\n",
    "            frame_idx = frame_properties[\"frame_idx\"]\n",
    "            if prev is None and next is None:\n",
    "                total_not_both += 1\n",
    "            elif prev is None:\n",
    "                total_not_only_prev += 1\n",
    "            elif next is None:\n",
    "                total_not_only_next += 1\n",
    "\n",
    "            data[token] = (prev, next, scene_token, frame_idx)\n",
    "\n",
    "    chain_results = {}\n",
    "\n",
    "    for token, (_, _, scene_token, _) in data.items():\n",
    "        if scene_token not in chain_results:\n",
    "            chain_results[scene_token] = {\n",
    "                \"total\": 0,\n",
    "                \"frames\": [token]\n",
    "            }\n",
    "        else:\n",
    "            chain_results[scene_token][\"frames\"].append(token)\n",
    "\n",
    "    for token, (prev, next, scene_token, frame_idx) in data.items(): \n",
    "        chain_results[scene_token][\"total\"] = len(chain_results[scene_token][\"frames\"])\n",
    "\n",
    "    print(\"\\n\", \"-\" * 15, \"split: \", split, \"-\" * 15)\n",
    "    chain_results = sorted(chain_results.items(), key=lambda x:int(x[1][\"total\"]))\n",
    "\n",
    "    print(\"No. Sequences with following number of frames: \")\n",
    "    for x, y in sorted(chain_results):\n",
    "        print(\"\\tscene token\", x, \"\\ttotal no frames: \\t\", y[\"total\"])\n",
    "\n",
    "    print(\"\\nNumber of sequences: \\t\\t\", len(chain_results))\n",
    "    print(\"Samples with no prev: \\t\\t\", total_not_only_prev)\n",
    "    print(\"Samples with no next: \\t\\t\", total_not_only_next)\n",
    "    print(\"Samples with no prev nor next: \\t\", total_not_both)\n",
    "\n",
    "\n",
    "    # fmt: off\n",
    "    print(\"\\nNo. Classes with following difficulty levels: \")\n",
    "    total_difficulty_stats = {x: {\"easy\": 0, \"moderate\": 0, \"hard\": 0} for x in CLASSES}\n",
    "    for scene_token, data in sequence_data.items():\n",
    "        for cls, counts in data.total_difficulty_stats.items():\n",
    "            for x, count in counts.items():\n",
    "                total_difficulty_stats[cls][x] += count\n",
    "    print(\"\\n{:<20} {:<15} {:<15} {:<15}\".format(\"Object Type\", \"easy\",\"moderate\",\"hard\"))\n",
    "    print(\"-\" * 60)\n",
    "    for cls, counts in total_difficulty_stats.items():\n",
    "        print (\"{:<20} {:<15} {:<15} {:<15}\".format(cls, counts[\"easy\"], counts[\"moderate\"], counts[\"hard\"]))\n",
    "    total_difficulty = sum([x[\"easy\"] for x in total_difficulty_stats.values()]) + sum([x[\"moderate\"] for x in total_difficulty_stats.values()]) + sum([x[\"hard\"] for x in total_difficulty_stats.values()])\n",
    "    difficulty_counts = [sum([x[\"easy\"] for x in total_difficulty_stats.values()]), sum([x[\"moderate\"] for x in total_difficulty_stats.values()]), sum([x[\"hard\"] for x in total_difficulty_stats.values()])]\n",
    "    print(\"{:<20} {:<15} {:<15} {:<15}\".format(\"Total (count)\", difficulty_counts[0], difficulty_counts[1], difficulty_counts[2]))\n",
    "    difficulty_ratios = [sum([x[\"easy\"] for x in total_difficulty_stats.values()])/total_difficulty, sum([x[\"moderate\"] for x in total_difficulty_stats.values()])/total_difficulty, sum([x[\"hard\"] for x in total_difficulty_stats.values()])/total_difficulty]\n",
    "    print(\"{:<20} {:<15.3f} {:<15.3f} {:<15.3f}\".format(\"Total (ratio)\", difficulty_ratios[0], difficulty_ratios[1], difficulty_ratios[2]))\n",
    "\n",
    "    print(\"\\nNo. Classes with following distances: \")\n",
    "    total_distance_stats = {x: {\"d<40\": 0, \"d40-50\": 0, \"d>50\": 0} for x in CLASSES}\n",
    "    for scene_token, data in sequence_data.items():\n",
    "        for cls, counts in data.total_distance_stats.items():\n",
    "            for x, count in counts.items():\n",
    "                total_distance_stats[cls][x] += count\n",
    "    print(\"\\n{:<20} {:<15} {:<15} {:<15}\".format(\"Object Type\", \"d <= 40m\",\"40 < d <= 50\",\"50 < d\"))\n",
    "    print(\"-\" * 60)\n",
    "    for cls, counts in total_distance_stats.items():\n",
    "        print (\"{:<20} {:<15} {:<15} {:<15}\".format(cls, counts[\"d<40\"], counts[\"d40-50\"], counts[\"d>50\"]))\n",
    "    total_distances = sum([x[\"d<40\"] for x in total_distance_stats.values()]) + sum([x[\"d40-50\"] for x in total_distance_stats.values()]) + sum([x[\"d>50\"] for x in total_distance_stats.values()])\n",
    "    distance_counts = [sum([x[\"d<40\"] for x in total_distance_stats.values()]), sum([x[\"d40-50\"] for x in total_distance_stats.values()]), sum([x[\"d>50\"] for x in total_distance_stats.values()])]\n",
    "    print(\"{:<20} {:<15} {:<15} {:<15}\".format(\"Total (count)\", distance_counts[0], distance_counts[1], distance_counts[2]))\n",
    "    distance_ratios = [sum([x[\"d<40\"] for x in total_distance_stats.values()])/total_distances, sum([x[\"d40-50\"] for x in total_distance_stats.values()])/total_distances, sum([x[\"d>50\"] for x in total_distance_stats.values()])/total_distances]\n",
    "    print(\"{:<20} {:<15.3f} {:<15.3f} {:<15.3f}\".format(\"Total (ratio)\", distance_ratios[0], distance_ratios[1], distance_ratios[2]))\n",
    "\n",
    "    print(\"\\nNo. Classes with following number of points: \")\n",
    "    total_points_stats = {x: {\"n<20\": 0, \"n20-50\": 0, \"n>50\": 0} for x in CLASSES}\n",
    "    for scene_token, data in sequence_data.items():\n",
    "        for cls, counts in data.total_num_points_stats.items():\n",
    "            for x, count in counts.items():\n",
    "                total_points_stats[cls][x] += count\n",
    "    print(\"\\n{:<20} {:<15} {:<15} {:<15}\".format(\"Object Type\", \"n <= 20\",\"20 < n <= 50\",\"50 < n\"))\n",
    "    print(\"-\" * 60)\n",
    "    for cls, counts in total_points_stats.items():\n",
    "        print (\"{:<20} {:<15} {:<15} {:<15}\".format(cls, counts[\"n<20\"], counts[\"n20-50\"], counts[\"n>50\"]))\n",
    "    total_ratios = sum([x[\"n<20\"] for x in total_points_stats.values()]) + sum([x[\"n20-50\"] for x in total_points_stats.values()]) + sum([x[\"n>50\"] for x in total_points_stats.values()])\n",
    "    points_counts = [sum([x[\"n<20\"] for x in total_points_stats.values()]), sum([x[\"n20-50\"] for x in total_points_stats.values()]), sum([x[\"n>50\"] for x in total_points_stats.values()])]\n",
    "    print(\"{:<20} {:<15} {:<15} {:<15} \".format(\"Total (count)\", points_counts[0], points_counts[1], points_counts[2]))\n",
    "    points_ratios = [sum([x[\"n<20\"] for x in total_points_stats.values()])/total_ratios, sum([x[\"n20-50\"] for x in total_points_stats.values()])/total_ratios, sum([x[\"n>50\"] for x in total_points_stats.values()])/total_ratios]\n",
    "    print(\"{:<20} {:<15.3f} {:<15.3f} {:<15.3f}\".format(\"Total (ratio)\", points_ratios[0], points_ratios[1], points_ratios[2]))\n",
    "\n",
    "    print(\"\\nNo. Classes with following occlusion levels: \")\n",
    "    total_occlusion_stats = {x: {\"NOT_OCCLUDED\": 0, \"PARTIALLY_OCCLUDED\": 0, \"MOSTLY_OCCLUDED\": 0, \"UNKNOWN\" : 0} for x in CLASSES}\n",
    "    for scene_token, data in sequence_data.items():\n",
    "        for cls, counts in data.total_occlusion_stats.items():\n",
    "            for x, count in counts.items():\n",
    "                total_occlusion_stats[cls][x] += count\n",
    "    print(\"\\n{:<20} {:<20} {:<20} {:<20} {:<20}\".format(\"Object Type\", \"NOT_OCCLUDED\",\"PARTIALLY_OCCLUDED\",\"MOSTLY_OCCLUDED\", \"UNKNOWN\"))\n",
    "    print(\"-\" * 100)\n",
    "    for cls, counts in total_occlusion_stats.items():\n",
    "        print (\"{:<20} {:<20} {:<20} {:<20} {:<20}\".format(cls, counts[\"NOT_OCCLUDED\"], counts[\"PARTIALLY_OCCLUDED\"], counts[\"MOSTLY_OCCLUDED\"], counts[\"UNKNOWN\"]))\n",
    "    total_occlusion = sum([x[\"NOT_OCCLUDED\"] for x in total_occlusion_stats.values()]) + sum([x[\"PARTIALLY_OCCLUDED\"] for x in total_occlusion_stats.values()]) + sum([x[\"MOSTLY_OCCLUDED\"] for x in total_occlusion_stats.values()]) + sum([x[\"UNKNOWN\"] for x in total_occlusion_stats.values()])\n",
    "    occlusion_counts = [sum([x[\"NOT_OCCLUDED\"] for x in total_occlusion_stats.values()]), sum([x[\"PARTIALLY_OCCLUDED\"] for x in total_occlusion_stats.values()]), sum([x[\"MOSTLY_OCCLUDED\"] for x in total_occlusion_stats.values()]), sum([x[\"UNKNOWN\"] for x in total_occlusion_stats.values()])]\n",
    "    print(\"{:<20} {:<20} {:<20} {:<20} {:<20}\".format(\"Total (count)\", occlusion_counts[0], occlusion_counts[1], occlusion_counts[2], occlusion_counts[3]))\n",
    "    occlusion_ratios = [sum([x[\"NOT_OCCLUDED\"] for x in total_occlusion_stats.values()])/total_occlusion, sum([x[\"PARTIALLY_OCCLUDED\"] for x in total_occlusion_stats.values()])/total_occlusion, sum([x[\"MOSTLY_OCCLUDED\"] for x in total_occlusion_stats.values()])/total_occlusion, sum([x[\"UNKNOWN\"] for x in total_occlusion_stats.values()])/total_occlusion]\n",
    "    print(\"{:<20} {:<20.3f} {:<20.3f} {:<20.3f} {:<20.3f}\".format(\"Total (ratio)\", occlusion_ratios[0], occlusion_ratios[1], occlusion_ratios[2], occlusion_ratios[3]))\n",
    "\n",
    "    return {\n",
    "        \"difficulty_ratios\": difficulty_ratios,\n",
    "        \"difficulty_counts\": difficulty_counts,\n",
    "        \"distance_ratios\": distance_ratios,\n",
    "        \"distance_counts\": distance_counts,\n",
    "        \"points_ratios\": points_ratios,\n",
    "        \"points_counts\": points_counts,\n",
    "        \"occlusion_ratios\": occlusion_ratios,\n",
    "        \"occlusion_counts\": occlusion_counts\n",
    "    }\n",
    "\n",
    "    # fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(overall_summary) -> None:\n",
    "    print(\"\\n{:<10} {:<15} {:<15} {:<15}\".format(\"Split\", \"easy\", \"moderate\", \"hard\"))\n",
    "    print(\"-\" * 55)\n",
    "    for split, data in overall_summary.items():\n",
    "        print (\"{:<10}| {:<15} {:<15} {:<15}\".format(split, f\"{data['difficulty_counts'][0]:<5} ({data['difficulty_ratios'][0]:.3f})\", f\"{data['difficulty_counts'][1]:<5} ({data['difficulty_ratios'][1]:.3f})\", f\"{data['difficulty_counts'][2]:<5} ({data['difficulty_ratios'][2]:.3f})\"))\n",
    "\n",
    "    print(\"\\n{:<10} {:<15} {:<15} {:<15}\".format(\"Split\", \"d <= 40m\",\"40 < d <= 50\",\"50 < d\"))\n",
    "    print(\"-\" * 55)\n",
    "    for split, data in overall_summary.items():\n",
    "        print (\"{:<10}| {:<15} {:<15} {:<15}\".format(split, f\"{data['distance_counts'][0]:<5} ({data['distance_ratios'][0]:.3f})\", f\"{data['distance_counts'][1]:<5} ({data['distance_ratios'][1]:.3f})\", f\"{data['distance_counts'][2]:<5} ({data['distance_ratios'][2]:.3f})\"))\n",
    "\n",
    "    print(\"\\n{:<10} {:<15} {:<15} {:<15}\".format(\"Split\", \"n <= 20\",\"20 < n <= 50\",\"50 < n\"))\n",
    "    print(\"-\" * 55)\n",
    "    for split, data in overall_summary.items():\n",
    "        print (\"{:<10}| {:<15} {:<15} {:<15}\".format(split, f\"{data['points_counts'][0]:<5} ({data['points_ratios'][0]:.3f})\", f\"{data['points_counts'][1]:<5} ({data['points_ratios'][1]:.3f})\", f\"{data['points_counts'][2]:<5} ({data['points_ratios'][2]:.3f})\"))\n",
    "\n",
    "    print(\"\\n{:<10} {:<20} {:<20} {:<20} {:<20}\".format(\"Split\", \"NOT_OCCLUDED\",\"PARTIALLY_OCCLUDED\",\"MOSTLY_OCCLUDED\", \"UNKNOWN\"))\n",
    "    print(\"-\" * 90)\n",
    "    for split, data in overall_summary.items():\n",
    "        print (\"{:<10}| {:<20} {:<20} {:<20} {:<20}\".format(split, f\"{data['occlusion_counts'][0]:<5} ({data['occlusion_ratios'][0]:.3f})\", f\"{data['occlusion_counts'][1]:<5} ({data['occlusion_ratios'][1]:.3f})\", f\"{data['occlusion_counts'][2]:<5} ({data['occlusion_ratios'][2]:.3f})\", f\"{data['occlusion_counts'][3]:<5} ({data['occlusion_ratios'][3]:.3f})\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_summary[\"train\"] = analyze(root_path, \"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_summary[\"val\"] = analyze(root_path, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(root_path, \"test\")):\n",
    "    overall_summary[\"test\"] = analyze(root_path, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(overall_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
