{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "from torchpack.utils.config import configs\n",
    "from mmdet3d.utils import recursive_eval\n",
    "from mmcv import Config\n",
    "import joblib\n",
    "from argparse import Namespace\n",
    "from tools.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = (\n",
    "    \"CAR\",\n",
    "    \"TRAILER\",\n",
    "    \"TRUCK\",\n",
    "    \"VAN\",\n",
    "    \"PEDESTRIAN\",\n",
    "    \"BUS\",\n",
    "    \"MOTORCYCLE\",\n",
    "    \"BICYCLE\",\n",
    "    \"EMERGENCY_VEHICLE\",\n",
    "    # \"OTHER\",\n",
    ")\n",
    "\n",
    "AP_DISTS = [\n",
    "    \"ap_dist_0.5\",\n",
    "    \"ap_dist_1.0\",\n",
    "    \"ap_dist_2.0\",\n",
    "    \"ap_dist_4.0\",\n",
    "]\n",
    "\n",
    "CLS_SEARCH_SPACE = {\n",
    "    \"CAR\": [8, 15],\n",
    "    \"TRAILER\": [0, 2],\n",
    "    \"TRUCK\": [0, 4],\n",
    "    \"VAN\": [0, 5],\n",
    "    \"PEDESTRIAN\": [0, 8],\n",
    "    \"BUS\": [0, 2],\n",
    "    \"MOTORCYCLE\": [0, 4],\n",
    "    \"BICYCLE\": [0, 4],\n",
    "    \"EMERGENCY_VEHICLE\": [0, 2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_map(checkpoint_folder_path: str, classes: list, ap_dists: list) -> float:\n",
    "    try:\n",
    "        json_file = [f for f in os.listdir(checkpoint_folder_path) if f.endswith(\".json\")][0]\n",
    "        json_file = os.path.join(checkpoint_folder_path, json_file)\n",
    "\n",
    "        data = []\n",
    "        with open(json_file, \"r\") as f:\n",
    "            for line in f:\n",
    "                data.append(json.loads(line))\n",
    "        data = data[-1]\n",
    "\n",
    "        class_ap = {x: 0 for x in classes}\n",
    "        for cls in classes:\n",
    "            all_ap_dists = []\n",
    "            for ap_dist in ap_dists:\n",
    "                all_ap_dists.append(data[f\"object/{cls}_{ap_dist}\"])\n",
    "            class_ap[cls] = np.mean(all_ap_dists)\n",
    "\n",
    "        map = data[\"object/map\"]\n",
    "        epoch = data[\"epoch\"]\n",
    "    except:\n",
    "        map = 0\n",
    "        class_ap = {x: 0 for x in classes}\n",
    "        epoch = 0\n",
    "    return map, class_ap, epoch\n",
    "\n",
    "\n",
    "def find_gtp_in_pipeline(pipeline: list) -> int:\n",
    "    for i, p in enumerate(pipeline):\n",
    "        if p[\"type\"] == \"ObjectPaste\":\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "\n",
    "def objective(\n",
    "    trial,\n",
    "    source_config_path: str,\n",
    "    tune_target_folder_path: str,\n",
    "    max_epochs: int,\n",
    "    n_gpus: int,\n",
    "    target_classes: list,\n",
    "    ap_dists: list,\n",
    "    cls_search_space: dict,\n",
    ") -> float:\n",
    "    params = {c: trial.suggest_int(c, v[0], v[1]) for c, v in cls_search_space.items()}\n",
    "    print(f\"Trial {trial.number} - Params: {params}\")\n",
    "\n",
    "    run_dir = os.path.join(tune_target_folder_path, f\"trial_{trial.number}\")\n",
    "\n",
    "    configs.load(source_config_path, recursive=True)\n",
    "\n",
    "    cfg = Config(recursive_eval(configs), filename=source_config_path)\n",
    "\n",
    "    gtp_idx = find_gtp_in_pipeline(cfg.data.train.dataset.pipeline)\n",
    "    cfg.data.train.dataset.pipeline[gtp_idx].db_sampler.sample_groups = params\n",
    "\n",
    "    tmp_config_path = os.path.join(tune_target_folder_path, \"tmp_config.yaml\")\n",
    "    if os.path.exists(tmp_config_path):\n",
    "        os.remove(tmp_config_path)\n",
    "\n",
    "    cfg.run_dir = run_dir\n",
    "    cfg.checkpoint_config.max_keep_ckpts = 0\n",
    "    cfg.runner.max_epochs = max_epochs\n",
    "    cfg.optimizer.lr = 2.0e-4\n",
    "    cfg.dump(tmp_config_path)\n",
    "\n",
    "    command = f\"torchpack dist-run -np {n_gpus} python tools/train.py {tmp_config_path} --run-dir {run_dir}\"\n",
    "    command += \" > /dev/null 2>&1\"\n",
    "    os.system(command)\n",
    "\n",
    "    map, _, epoch = read_map(run_dir, target_classes, ap_dists)\n",
    "\n",
    "    trial.report(map, epoch)\n",
    "\n",
    "    return map\n",
    "\n",
    "\n",
    "def save_results(df, study, save_path: str):\n",
    "    df.to_csv(os.path.join(save_path, \"results.csv\"))\n",
    "    fig = optuna.visualization.plot_param_importances(study)\n",
    "    fig.write_image(os.path.join(save_path, \"param_importances.png\"))\n",
    "    fig = optuna.visualization.plot_optimization_history(study)\n",
    "    fig.write_image(os.path.join(save_path, \"optimization_history.png\"))\n",
    "    fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "    fig.write_image(os.path.join(save_path, \"parallel_coordinate.png\"))\n",
    "\n",
    "\n",
    "def tune(\n",
    "    source_config_path: str,\n",
    "    tune_target_folder_path: str,\n",
    "    n_trials: int,\n",
    "    n_gpus: int,\n",
    "    max_epochs: int,\n",
    "    classes: list,\n",
    "    ap_dists: list,\n",
    "    cls_search_space: dict,\n",
    "):\n",
    "    os.makedirs(tune_target_folder_path, exist_ok=True)\n",
    "    run_id = os.path.basename(tune_target_folder_path)\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=run_id,\n",
    "        direction=\"maximize\",\n",
    "        sampler=optuna.samplers.TPESampler(),\n",
    "    )\n",
    "\n",
    "    study.optimize(\n",
    "        lambda trial: objective(\n",
    "            trial,\n",
    "            source_config_path,\n",
    "            tune_target_folder_path,\n",
    "            max_epochs,\n",
    "            n_gpus,\n",
    "            classes,\n",
    "            ap_dists,\n",
    "            cls_search_space,\n",
    "        ),\n",
    "        n_trials=n_trials,\n",
    "    )\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "\n",
    "    for key, value in best_trial.params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "    joblib.dump(study, os.path.join(tune_target_folder_path, \"study.pkl\"))\n",
    "\n",
    "    df = study.trials_dataframe()\n",
    "    save_results(df, study, tune_target_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_config_path = (\n",
    "    \"configs/tumtraf-i/baseline/transfusion/lidar/voxelnet-1600g-0xy1-0z20-gtp15.yaml\"\n",
    ")\n",
    "tune_target_folder_path = \"checkpoints/tune/tumtraf-i\"\n",
    "max_epochs = 5\n",
    "n_trials = 20\n",
    "n_gpus = 2\n",
    "tune(\n",
    "    source_config_path,\n",
    "    tune_target_folder_path,\n",
    "    n_trials,\n",
    "    n_gpus,\n",
    "    max_epochs,\n",
    "    CLASSES,\n",
    "    AP_DISTS,\n",
    "    CLS_SEARCH_SPACE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
