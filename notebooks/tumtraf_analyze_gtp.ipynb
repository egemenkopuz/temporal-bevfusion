{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pickle\n",
    "import sys\n",
    "from typing import Dict, List\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from mmcv import Config\n",
    "from torchpack.utils.config import configs\n",
    "from mmdet3d.utils import recursive_eval\n",
    "import random\n",
    "from mmdet3d.datasets import build_dataloader, build_dataset\n",
    "import torch\n",
    "import mmcv\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet3d.datasets.pipelines import (\n",
    "    LoadMultiViewImageFromFiles,\n",
    "    LoadPointsFromFile,\n",
    "    LoadAnnotations3D,\n",
    ")\n",
    "from mmcv.utils import build_from_cfg\n",
    "from mmdet3d.datasets.builder import OBJECTSAMPLERS\n",
    "from mmdet3d.core.bbox import box_np_ops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/mmdet3d\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumtraf_i_dbinfos_path = \"data/tumtraf-i-bevfusion/tumtraf_dbinfos_train.pkl\"\n",
    "default_config_path = \"notebooks/resources/tumtraf-i_test_config.yaml\"\n",
    "\n",
    "filter_by_min_points = 5\n",
    "\n",
    "assert os.path.exists(tumtraf_i_dbinfos_path) , \"tumtraf-i dbinfos not found\"\n",
    "assert os.path.exists(default_config_path), \"config not found\"\n",
    "\n",
    "# load pickle\n",
    "with open(tumtraf_i_dbinfos_path, \"rb\") as f:\n",
    "    tumtraf_i_dbinfos = pickle.load(f)\n",
    "\n",
    "# load config\n",
    "configs.load(default_config_path, recursive=True)\n",
    "cfg = Config(recursive_eval(configs), filename=default_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in tumtraf_i_dbinfos.items():\n",
    "    num_points = []\n",
    "    distances = []\n",
    "    difficulty_counts = defaultdict(int)\n",
    "    filtered_num_sample = 0\n",
    "\n",
    "    for value in values:\n",
    "        num_points.append(value[\"num_points_in_gt\"])\n",
    "        distances.append(value[\"distance\"])\n",
    "        difficulty_counts[value[\"difficulty\"]] += 1\n",
    "\n",
    "        if value[\"num_points_in_gt\"] < filter_by_min_points:\n",
    "            filtered_num_sample += 1\n",
    "\n",
    "    avg_num_points = np.mean(num_points)\n",
    "    min_num_points = np.min(num_points)\n",
    "    max_num_points = np.max(num_points)\n",
    "    avg_distance  = np.mean(distances)\n",
    "    min_distance = np.min(distances)\n",
    "    max_distance = np.max(distances)\n",
    "\n",
    "    difficulty_counts = sorted(difficulty_counts.items(), key=lambda x: x[0])\n",
    "\n",
    "    # print(\"=\"*60)\n",
    "    # print(key)\n",
    "    # print(\"=\"*60)\n",
    "    # print(f\"{'samples':<12} - total: {len(values):<8} - {'filtered: ' + str(filtered_num_sample):<15} - {'kept: ' + str(len(values) - filtered_num_sample):<10}\")\n",
    "    # print(f\"{'num points':<12} - avg: {avg_num_points:<10.3f} - min: {min_num_points:<10} - max: {max_num_points:<10}\")\n",
    "    # print(f\"{'distance':<12} - avg: {avg_distance:<10.3f} - min: {min_distance:<10.3f} - max: {max_distance:<10.3f}\")\n",
    "    # diff_string = \" - \".join(f\"{x}: {y:<12}\" for x, y in dict(difficulty_counts).items())\n",
    "    # print(f\"{'difficulty':<12} - {diff_string}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seeds\n",
    "random.seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "torch.manual_seed(cfg.seed)\n",
    "dataset = build_dataset(cfg.data.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CAR': 3, 'TRAILER': 2, 'TRUCK': 4, 'VAN': 5, 'PEDESTRIAN': 7, 'BUS': 2, 'MOTORCYCLE': 5, 'BICYCLE': 5, 'EMERGENCY_VEHICLE': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1920/1920 [01:28<00:00, 21.58it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "CLASSES = [\n",
    "    \"CAR\",\n",
    "    \"TRAILER\",\n",
    "    \"TRUCK\",\n",
    "    \"VAN\",\n",
    "    \"PEDESTRIAN\",\n",
    "    \"BUS\",\n",
    "    \"MOTORCYCLE\",\n",
    "    \"BICYCLE\",\n",
    "    \"EMERGENCY_VEHICLE\",\n",
    "]\n",
    "\n",
    "\n",
    "class CustomObjectPaste:\n",
    "    def __init__(self, db_sampler, sample_2d=False, stop_epoch=None):\n",
    "        self.sampler_cfg = db_sampler\n",
    "        self.sample_2d = sample_2d\n",
    "        if \"type\" not in db_sampler.keys():\n",
    "            db_sampler[\"type\"] = \"DataBaseSampler\"\n",
    "        self.db_sampler = build_from_cfg(db_sampler, OBJECTSAMPLERS)\n",
    "        self.epoch = -1\n",
    "        self.stop_epoch = stop_epoch\n",
    "\n",
    "        self.total_prev = 0\n",
    "        self.total_after = 0\n",
    "\n",
    "        self.prev_total_class_counts = np.asarray([0] * len(CLASSES))\n",
    "        self.after_total_class_counts = np.asarray([0] * len(CLASSES))\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_points_in_boxes(points, boxes):\n",
    "        \"\"\"Remove the points in the sampled bounding boxes.\n",
    "        Args:\n",
    "            points (:obj:`BasePoints`): Input point cloud array.\n",
    "            boxes (np.ndarray): Sampled ground truth boxes.\n",
    "        Returns:\n",
    "            np.ndarray: Points with those in the boxes removed.\n",
    "        \"\"\"\n",
    "        masks = box_np_ops.points_in_rbbox(points.coord.numpy(), boxes)\n",
    "        points = points[np.logical_not(masks.any(-1))]\n",
    "        return points\n",
    "\n",
    "    def __call__(self, data):\n",
    "        \"\"\"Call function to sample ground truth objects to the data.\n",
    "        Args:\n",
    "            data (dict): Result dict from loading pipeline.\n",
    "        Returns:\n",
    "            dict: Results after object sampling augmentation, \\\n",
    "                'points', 'gt_bboxes_3d', 'gt_labels_3d' keys are updated \\\n",
    "                in the result dict.\n",
    "        \"\"\"\n",
    "        # if self.stop_epoch is not None and self.epoch >= self.stop_epoch:\n",
    "        #     return data\n",
    "        gt_bboxes_3d = data[\"gt_bboxes_3d\"]\n",
    "        gt_labels_3d = data[\"gt_labels_3d\"]\n",
    "\n",
    "        before_count = gt_bboxes_3d.tensor.numpy().shape[0]\n",
    "        before_class_counts = [0] * len(CLASSES)\n",
    "        for x in gt_labels_3d:\n",
    "            before_class_counts[x] += 1\n",
    "\n",
    "        # change to float for blending operation\n",
    "        points = data[\"points\"]\n",
    "        if self.sample_2d:\n",
    "            img = data[\"img\"]\n",
    "            gt_bboxes_2d = data[\"gt_bboxes\"]\n",
    "            # Assume for now 3D & 2D bboxes are the same\n",
    "            sampled_dict = self.db_sampler.sample_all(\n",
    "                gt_bboxes_3d.tensor.numpy(),\n",
    "                gt_labels_3d,\n",
    "                gt_bboxes_2d=gt_bboxes_2d,\n",
    "                img=img,\n",
    "            )\n",
    "        else:\n",
    "            sampled_dict = self.db_sampler.sample_all(\n",
    "                gt_bboxes_3d.tensor.numpy(), gt_labels_3d, img=None\n",
    "            )\n",
    "\n",
    "        if sampled_dict is not None:\n",
    "            sampled_gt_bboxes_3d = sampled_dict[\"gt_bboxes_3d\"]\n",
    "            sampled_points = sampled_dict[\"points\"]\n",
    "            sampled_gt_labels = sampled_dict[\"gt_labels_3d\"]\n",
    "\n",
    "            gt_labels_3d = np.concatenate([gt_labels_3d, sampled_gt_labels], axis=0)\n",
    "            gt_bboxes_3d = gt_bboxes_3d.new_box(\n",
    "                np.concatenate([gt_bboxes_3d.tensor.numpy(), sampled_gt_bboxes_3d])\n",
    "            )\n",
    "\n",
    "            after_count = gt_bboxes_3d.tensor.numpy().shape[0]\n",
    "            after_class_counts = [0] * len(CLASSES)\n",
    "            for x in gt_labels_3d:\n",
    "                after_class_counts[x] += 1\n",
    "\n",
    "            points = self.remove_points_in_boxes(points, sampled_gt_bboxes_3d)\n",
    "            # check the points dimension\n",
    "            points = points.cat([sampled_points, points])\n",
    "\n",
    "            if self.sample_2d:\n",
    "                sampled_gt_bboxes_2d = sampled_dict[\"gt_bboxes_2d\"]\n",
    "                gt_bboxes_2d = np.concatenate([gt_bboxes_2d, sampled_gt_bboxes_2d]).astype(\n",
    "                    np.float32\n",
    "                )\n",
    "\n",
    "                data[\"gt_bboxes\"] = gt_bboxes_2d\n",
    "                data[\"img\"] = sampled_dict[\"img\"]\n",
    "\n",
    "        data[\"gt_bboxes_3d\"] = gt_bboxes_3d\n",
    "        data[\"gt_labels_3d\"] = gt_labels_3d.astype(np.long)\n",
    "        data[\"points\"] = points\n",
    "\n",
    "        if before_count != after_count:\n",
    "            # print(f\"b: {before_count:<10} {before_class_counts}\")\n",
    "            # print(f\"a: {after_count:<10} {after_class_counts}\")\n",
    "            self.total_prev += before_count\n",
    "            self.total_after += after_count\n",
    "            self.prev_total_class_counts += np.array(before_class_counts)\n",
    "            self.after_total_class_counts += np.array(after_class_counts)\n",
    "\n",
    "        return data\n",
    "\n",
    "\n",
    "custom_sample_group = {\n",
    "    \"CAR\": 3,\n",
    "    \"TRAILER\": 2,\n",
    "    \"TRUCK\": 4,\n",
    "    \"VAN\": 5,\n",
    "    \"PEDESTRIAN\": 7,\n",
    "    \"BUS\": 2,\n",
    "    \"MOTORCYCLE\": 5,\n",
    "    \"BICYCLE\": 5,\n",
    "    \"EMERGENCY_VEHICLE\": 3,\n",
    "}\n",
    "cfg.data.train.dataset.pipeline[3].db_sampler.sample_groups = custom_sample_group\n",
    "print(cfg.data.train.dataset.pipeline[3].db_sampler.sample_groups)\n",
    "\n",
    "pipeline = Compose(\n",
    "    [\n",
    "        LoadMultiViewImageFromFiles(),\n",
    "        LoadPointsFromFile(\"LIDAR\", 5, 4),\n",
    "        LoadAnnotations3D(),\n",
    "    ]\n",
    ")\n",
    "gtp = CustomObjectPaste(cfg.data.train.dataset.pipeline[3].db_sampler, stop_epoch=99)\n",
    "total_len = len(dataset.dataset)\n",
    "\n",
    "for idx in tqdm(range(total_len)):\n",
    "    input_dict = dataset.dataset.get_data_info(idx)\n",
    "    dataset.dataset.pre_pipeline(input_dict)\n",
    "    input_dict = pipeline(input_dict)\n",
    "    input_dict = gtp(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inital total 30202 avg 15.730\n",
      "final total 61378 avg 31.968\n",
      "\n",
      "total     CAR         TRAILER     TRUCK       VAN         PEDESTRIAN  BUS         MOTORCYCLE  BICYCLE     EMERGENCY_VEHICLE\n",
      "==============================================================================================================\n",
      "intial    18213       2454        2128        3508        2013        714         526         460         186         \n",
      "augment   +120        +901        +3319       +3704       +7555       +2138       +3345       +6366       +3728       \n",
      "final     18333       3355        5447        7212        9568        2852        3871        6826        3914        \n",
      "\n",
      "avg/frame CAR         TRAILER     TRUCK       VAN         PEDESTRIAN  BUS         MOTORCYCLE  BICYCLE     EMERGENCY_VEHICLE\n",
      "==============================================================================================================\n",
      "intial    9.486       1.278       1.108       1.827       1.048       0.372       0.274       0.240       0.097       \n",
      "final     9.548       1.747       2.837       3.756       4.983       1.485       2.016       3.555       2.039       \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"inital total\", gtp.total_prev, \"avg\", f\"{gtp.total_prev / total_len:.3f}\")\n",
    "print(\"final total\", gtp.total_after, \"avg\", f\"{gtp.total_after / total_len:.3f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "print(f\"{'total':<10}\" + \"\".join(f\"{x:<12}\" for x in CLASSES))\n",
    "print(\"=\"*110)\n",
    "print(f\"{'intial':<10}\" +\"\".join(f\"{x:<12}\" for x in gtp.prev_total_class_counts))\n",
    "print(f\"{'augment':<10}\" +\"\".join(f\"{'+' + str(x):<12}\" for x in gtp.after_total_class_counts - gtp.prev_total_class_counts))\n",
    "print(f\"{'final':<10}\" +\"\".join(f\"{x:<12}\" for x in gtp.after_total_class_counts))\n",
    "\n",
    "print()\n",
    "# print avg\n",
    "print(f\"{'avg/frame':<10}\" + \"\".join(f\"{x:<12}\" for x in CLASSES))\n",
    "print(\"=\"*110)\n",
    "print(f\"{'intial':<10}\" +\"\".join(f\"{x / total_len:<12.3f}\" for x in gtp.prev_total_class_counts))\n",
    "print(f\"{'final':<10}\" +\"\".join(f\"{x / total_len:<12.3f}\" for x in gtp.after_total_class_counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
