{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as f\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "import time\n",
    "from mmdet3d.models.temporal import ConvLSTM, ConvGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seqs = 3\n",
    "hidden_size = 256\n",
    "channels_img = 256\n",
    "size_image = 200\n",
    "max_epoch = 1\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvLSTM(\n",
      "  (cell_list): ModuleList(\n",
      "    (0): ConvLSTMCell(\n",
      "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_lstm = ConvLSTM(\n",
    "    in_channels=256,\n",
    "    hidden_channels=[256], # hparam\n",
    "    kernel_size=[3,3],\n",
    "    batch_first=True,\n",
    "    bias=True,\n",
    "    return_all_layers=False,\n",
    ")\n",
    "\n",
    "conv_lstm.eval()\n",
    "\n",
    "print(conv_lstm.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvGRU(\n",
      "  (cell_list): ModuleList(\n",
      "    (0): ConvGRUCell(\n",
      "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv_ct): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "conv_gru = ConvGRU(\n",
    "    in_channels=256,\n",
    "    hidden_channels=[256], # hparam\n",
    "    kernel_size=[3,3],\n",
    "    batch_first=True,\n",
    "    bias=True,\n",
    "    return_all_layers=False,\n",
    ")\n",
    "\n",
    "conv_gru.eval()\n",
    "\n",
    "print(conv_gru.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU(256, 256, batch_first=True)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import GRU\n",
    "\n",
    "torch_gru = GRU(\n",
    "    input_size=256,\n",
    "    hidden_size=256,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    "    bidirectional=False,\n",
    ")   \n",
    "print(torch_gru.__repr__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_feat.shape torch.Size([6, 256, 200, 200])\n",
      "prev_feat.shape torch.Size([6, 2, 256, 200, 200])\n",
      "curr_feat.shape torch.Size([6, 1, 256, 200, 200])\n",
      "x.shape torch.Size([6, 3, 256, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "# B, C, H, W\n",
    "# 1, 256, 200, 200\n",
    "batch_size = 6\n",
    "queue_length = 3\n",
    "curr_feat = torch.rand(batch_size, 256, 200, 200)\n",
    "print(\"curr_feat.shape\", curr_feat.shape)\n",
    "prev_feat = [torch.rand(batch_size, 256, 200, 200) for _ in range(queue_length - 1)]\n",
    "\n",
    "# stack the previous features -> B, T, C, H, W\n",
    "prev_feat = torch.stack(prev_feat, dim=1)\n",
    "# stack the current features -> B, C, H, W -> B, 1, C, H, W\n",
    "print(\"prev_feat.shape\", prev_feat.shape)\n",
    "curr_feat = curr_feat.unsqueeze(1)\n",
    "print(\"curr_feat.shape\", curr_feat.shape)\n",
    "x = torch.cat((prev_feat, curr_feat), dim=1)\n",
    "print(\"x.shape\", x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params_conv_lstm 4719616 100%\n",
      "n_params_conv_gru 3539712 66.67%\n",
      "n_params_torch_gru 394752 -995.59%\n"
     ]
    }
   ],
   "source": [
    "n_params_conv_lstm = get_n_params(conv_lstm)\n",
    "n_params_conv_gru = get_n_params(conv_gru)\n",
    "n_params_torch_gru = get_n_params(torch_gru)\n",
    "gru_decrease_perc = (n_params_conv_lstm - n_params_conv_gru) / n_params_conv_gru * 100\n",
    "torch_gru_decrease_perc = (n_params_conv_lstm - n_params_torch_gru) / n_params_torch_gru * 100\n",
    "# increase in percetange from gru to lstm\n",
    "print(\"n_params_conv_lstm\", n_params_conv_lstm, \"100%\")\n",
    "print(\"n_params_conv_gru\", n_params_conv_gru, f\"{100 - gru_decrease_perc:.2f}%\")\n",
    "print(\"n_params_torch_gru\", n_params_torch_gru, f\"{100 - torch_gru_decrease_perc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_time = time.time()\n",
    "out = conv_lstm(x)\n",
    "print(\"conv_lstm time\", time.time() - curr_time)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_time = time.time()\n",
    "out = conv_gru(x)\n",
    "print(\"conv_gru time\", time.time() - curr_time)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/mmdet3d/notebooks/temporal_model_implementation.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6567656d656e2d626576667573696f6e2d646576222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3133312e3135392e36312e313232227d7d/root/mmdet3d/notebooks/temporal_model_implementation.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m curr_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6567656d656e2d626576667573696f6e2d646576222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3133312e3135392e36312e313232227d7d/root/mmdet3d/notebooks/temporal_model_implementation.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m out \u001b[39m=\u001b[39m torch_gru(x)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6567656d656e2d626576667573696f6e2d646576222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3133312e3135392e36312e313232227d7d/root/mmdet3d/notebooks/temporal_model_implementation.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtorch_gru time\u001b[39m\u001b[39m\"\u001b[39m, time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m curr_time)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6567656d656e2d626576667573696f6e2d646576222c2273657474696e6773223a7b22686f7374223a227373683a2f2f3133312e3135392e36312e313232227d7d/root/mmdet3d/notebooks/temporal_model_implementation.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(out[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/.pyenv/versions/3.8.17/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/.pyenv/versions/3.8.17/lib/python3.8/site-packages/torch/nn/modules/rnn.py:847\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 847\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    848\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    850\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m/.pyenv/versions/3.8.17/lib/python3.8/site-packages/torch/nn/modules/rnn.py:229\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    230\u001b[0m     expected_hidden_size \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes)\n\u001b[1;32m    232\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m/.pyenv/versions/3.8.17/lib/python3.8/site-packages/torch/nn/modules/rnn.py:201\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    199\u001b[0m expected_input_dim \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m3\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m!=\u001b[39m expected_input_dim:\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m    205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 5"
     ]
    }
   ],
   "source": [
    "curr_time = time.time()\n",
    "out = torch_gru(x)\n",
    "print(\"torch_gru time\", time.time() - curr_time)\n",
    "print(out[0].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
